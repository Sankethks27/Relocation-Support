{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea52c81-0589-44eb-983b-e867df6c74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np \n",
    "import json\n",
    "import requests\n",
    "from pandas.io.json import json_normalize \n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import folium \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('All libraries have been imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2c1a3-3833-4172-83c9-cf6a36199100",
   "metadata": {},
   "outputs": [],
   "source": [
    "address1 = 'Oakland, California'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"foursquare_agent\")\n",
    "location1 = geolocator.geocode(address1)\n",
    "latitude1 = location1.latitude\n",
    "longitude1 = location1.longitude\n",
    "print('The geograpical coordinate of {} are {}, {}.'.format(address1, latitude1, longitude1))\n",
    "\n",
    "address2 = 'Emeryville, California'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"foursquare_agent\")\n",
    "location2 = geolocator.geocode(address2)\n",
    "latitude2 = location2.latitude\n",
    "longitude2 = location2.longitude\n",
    "print('The geograpical coordinate of {} are {}, {}.'.format(address2, latitude2, longitude2))\n",
    "\n",
    "address3 = 'San Diego, California'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"foursquare_agent\")\n",
    "location3 = geolocator.geocode(address3)\n",
    "latitude3 = location3.latitude\n",
    "longitude3 = location3.longitude\n",
    "print('The geograpical coordinate of {} are {}, {}.'.format(address3, latitude3, longitude3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0509d97-63b0-45df-aaa5-6364afa092f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '' # your Foursquare ID\n",
    "CLIENT_SECRET = '' # your Foursquare Secret\n",
    "VERSION = '' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)\n",
    "\n",
    "\n",
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "radius = 1000 # define radius\n",
    "\n",
    "# create URLs\n",
    "url1 = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    latitude1, \n",
    "    longitude1, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "\n",
    "\n",
    "# create URLs\n",
    "url2 = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    latitude2, \n",
    "    longitude2, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "\n",
    "\n",
    "# create URLs\n",
    "url3 = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    latitude3, \n",
    "    longitude3, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "\n",
    "print(url1, url2, url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667dbc7-c0ae-4fa8-b0f1-39036db05f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the data from the generated URLs\n",
    "\n",
    "results1 = requests.get(url1).json()\n",
    "results1\n",
    "\n",
    "results2 = requests.get(url2).json()\n",
    "results2\n",
    "\n",
    "results3 = requests.get(url3).json()\n",
    "results3\n",
    "\n",
    "# function that extracts the category of the venue\n",
    "\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']\n",
    "    \n",
    "\n",
    "# FIRST CITY   \n",
    "\n",
    "venues1 = results1['response']['groups'][0]['items']\n",
    "nearby_venues1 = pd.json_normalize(venues1) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns1 = ['venue.name', 'venue.categories', 'venue.location.lat', \n",
    "                    'venue.location.lng', 'venue.id']\n",
    "nearby_venues1 = nearby_venues1.loc[:, filtered_columns1]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues1['venue.categories'] = nearby_venues1.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues1.columns = [col.split(\".\")[-1] for col in nearby_venues1.columns]\n",
    "\n",
    "# SECOND CITY\n",
    "\n",
    "venues2 = results2['response']['groups'][0]['items']\n",
    "nearby_venues2 = pd.json_normalize(venues2) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns2 = ['venue.name', 'venue.categories', 'venue.location.lat', \n",
    "                    'venue.location.lng', 'venue.id']\n",
    "nearby_venues2 = nearby_venues2.loc[:, filtered_columns2]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues2['venue.categories'] = nearby_venues2.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues2.columns = [col.split(\".\")[-1] for col in nearby_venues2.columns]\n",
    "\n",
    "# THIRD CITY\n",
    "\n",
    "venues3 = results3['response']['groups'][0]['items']\n",
    "nearby_venues3 = pd.json_normalize(venues3) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns3 = ['venue.name', 'venue.categories', 'venue.location.lat', \n",
    "                    'venue.location.lng', 'venue.id']\n",
    "nearby_venues3 = nearby_venues3.loc[:, filtered_columns3]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues3['venue.categories'] = nearby_venues3.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues3.columns = [col.split(\".\")[-1] for col in nearby_venues3.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('{} venues for Oakland, California were returned by Foursquare.'.format(nearby_venues1.shape[0]))\n",
    "print()\n",
    "print('{} venues for Emeryville, California were returned by Foursquare.'.format(nearby_venues2.shape[0]))\n",
    "print()\n",
    "print('{} venues for San Diego, California were returned by Foursquare.'.format(nearby_venues3.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f9777-73ad-4b00-8242-c52ad34956a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add locations data to the data sets of each city\n",
    "\n",
    "nearby_venues1['city'] = 'Oakland'\n",
    "nearby_venues2['city'] = 'Emeryville'\n",
    "nearby_venues3['city'] = 'San Diego'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b348e62-af46-4bc6-9b44-524920da7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the three cities into one data set\n",
    "\n",
    "nearby_venues = nearby_venues1.copy()\n",
    "nearby_venues = nearby_venues.append(nearby_venues2)\n",
    "nearby_venues = nearby_venues.append(nearby_venues3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f046f-04ae-4de9-8150-0f8fd35131de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb96c6-b5db-438c-a6cf-b2d8d65794ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues['categories'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd47d0-d2e7-479d-a3ae-20c4b82ef959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check list and manually remove all non-restaurant data\n",
    "\n",
    "nearby_venues['categories'].unique()\n",
    "\n",
    "removal_list = ['Clothing Store','Bar','Brewery', \n",
    "                'Comic Shop', 'Yoga Studio','Caf√©', \n",
    "                'Coffee Shop', 'Tiki Bar', 'Music Venue', \n",
    "                'Wine Bar',  'Cocktail Bar', 'Dance Studio', \n",
    "                'Gym / Fitness Center','Beer Bar', \n",
    "                'Bubble Tea Shop', 'Nightclub', 'Food Court', \n",
    "                'Ice Cream Shop', 'Cupcake Shop', 'Skating Rink', \n",
    "                'Dessert Shop', 'Climbing Gym', 'Bakery', \n",
    "                'Farmers Market', 'Gay Bar','Beer Garden',\n",
    "                'Tea Room','Arts & Crafts Store', 'Grocery Store', \n",
    "                'Sports Bar', 'Museum', 'Street Food Gathering', \n",
    "                'Library', 'Skate Park', 'Movie Theater','Park', \n",
    "                'Gym', 'Stadium', 'Furniture / Home Store', 'Discount Store', \n",
    "                'Playground', 'Cosmetics Shop', 'Casino', \n",
    "                'Pet Store','Electronics Store', 'Snack Place',\n",
    "                'Salon / Barbershop', 'Shopping Plaza', 'Deli / Bodega', \n",
    "                'Candy Store', 'Liquor Store', 'Hotel', \n",
    "                'Shoe Store', 'Bookstore', 'Shopping Mall', \n",
    "                'Dive Bar', 'Video Game Store', 'Pharmacy', \n",
    "                'Accessories Store', 'Lingerie Store', 'Mobile Phone Shop', \n",
    "                'Pool Hall', 'Juice Bar', 'Kids Store', \n",
    "                'Supplement Shop', 'Big Box Store', 'Mattress Store', \n",
    "                'Hardware Store', 'Paper / Office Supplies Store', 'Theater', \n",
    "                'Business Service', 'Donut Shop', 'Beer Store', \n",
    "                'Lounge', 'Health Food Store', 'Pedestrian Plaza', \n",
    "                'Hookah Bar', 'Concert Hall', 'Chocolate Shop', \n",
    "                'Hostel', 'Convenience Store', 'Pub', \n",
    "                'Plaza', 'Comedy Club', 'Speakeasy', \n",
    "                'Tattoo Parlor', 'Massage Studio']\n",
    "\n",
    "nearby_venues = nearby_venues[~nearby_venues['categories'].isin(removal_list)]\n",
    "\n",
    "nearby_venues['categories'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c465b-1a1c-49dd-b9ea-9a161ea1d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up to pull the likes from the API based on venue ID\n",
    "\n",
    "url_list = []\n",
    "like_list = []\n",
    "json_list = []\n",
    "\n",
    "for i in list(nearby_venues.id):\n",
    "    venue_url = 'https://api.foursquare.com/v2/venues/{}/likes?client_id={}&client_secret={}&v={}'.format(i, CLIENT_ID, CLIENT_SECRET, VERSION)\n",
    "    url_list.append(venue_url)\n",
    "for link in url_list:\n",
    "    result = requests.get(link).json()\n",
    "    likes = result['response']['likes']['count']\n",
    "    like_list.append(likes)\n",
    "print(like_list)\n",
    "\n",
    "\n",
    "nearby_venues['likes'] = like_list\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67761fb-60d5-498c-984c-fbd79b4d240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9ac79-a73b-49bc-90ba-abf6d7890c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is really the raw dataset now so let us rename it something more appropriate\n",
    "\n",
    "raw_dataset = nearby_venues\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6223f9f-3069-43d1-a70f-97aab7b08979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the raw dataset shows that there may be too many different types of cuisines\n",
    "\n",
    "raw_dataset['categories'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5b44a-ae33-4803-b21b-ae5b686f2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can group some cuisines together to make a better categorical variable\n",
    "\n",
    "european = ['Mediterranean Restaurant', 'Scandinavian Restaurant', 'Pizza Place',\n",
    "       'French Restaurant', 'Falafel Restaurant', 'Italian Restaurant',\n",
    "       'Turkish Restaurant']\n",
    "\n",
    "latin = ['Mexican Restaurant', 'Taco Place', 'Brazilian Restaurant', \n",
    "          'Burrito Place']\n",
    "\n",
    "asian = ['Japanese Restaurant', 'Vietnamese Restaurant', 'Chinese Restaurant',\n",
    "         'Hot Dog Joint', 'Hotpot Restaurant', 'Indian Restaurant',\n",
    "         'Thai Restaurant', 'Dumpling Restaurant', 'Dim Sum Restaurant',\n",
    "         'Asian Restaurant', 'Filipino Restaurant', 'Sushi Restaurant',\n",
    "         'Ramen Restaurant']\n",
    "\n",
    "american = ['Vegetarian / Vegan Restaurant', 'Seafood Restaurant', 'Caribbean Restaurant',\n",
    "           'Burger Joint', 'American Restaurant', 'New American Restaurant',\n",
    "            'Southern / Soul Food Restaurant', 'Diner']\n",
    "\n",
    "casual = ['Bagel Shop', 'Sandwich Place', 'Fried Chicken Joint', \n",
    "          'Breakfast Spot', 'Wings Joint', 'Fast Food Restaurant',\n",
    "          'Theme Restaurant']\n",
    "\n",
    "def conditions(s):\n",
    "    if s['categories'] in european:\n",
    "        return 'european'\n",
    "    if s['categories'] in latin:\n",
    "        return 'latin'\n",
    "    if s['categories'] in asian:\n",
    "        return 'asian'\n",
    "    if s['categories'] in american:\n",
    "        return 'american'\n",
    "    if s['categories'] in casual:\n",
    "        return 'casual'\n",
    "\n",
    "raw_dataset['categories_classified'] = raw_dataset.apply(conditions, axis=1)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80057842-0cdd-44b2-b46e-04179af4b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check to make sure categories_classified has been created correctly\n",
    "\n",
    "pd.crosstab(index = raw_dataset[\"categories_classified\"],\n",
    "            columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95399a6-c1fb-4905-b00c-4ece134fa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['likes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac03932-8578-462b-8b74-48e7d450f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to bin for us\n",
    "\n",
    "def rankings(df):\n",
    "    \n",
    "    if df['likes'] <= 60:\n",
    "        return 3\n",
    "    \n",
    "    elif df['likes'] <= 100:\n",
    "        return 2\n",
    "    \n",
    "    elif df['likes'] > 100:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeae7af-a324-47fe-8f5e-8e9d44496aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rankings function to dataset\n",
    "\n",
    "raw_dataset['ranking'] = raw_dataset.apply(rankings, axis=1)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0081b-4345-4213-a1f1-0839bf7d4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies for linear regression modelling\n",
    "\n",
    "# one hot encoding\n",
    "reg_dataset = pd.get_dummies(raw_dataset[['categories_classified', \n",
    "                                          'city',]], \n",
    "                               prefix=\"\", \n",
    "                               prefix_sep=\"\")\n",
    "\n",
    "# add name, ranking, and likes columns back to dataframe\n",
    "reg_dataset['ranking'] = raw_dataset['ranking']\n",
    "reg_dataset['likes'] = raw_dataset['likes']\n",
    "reg_dataset['name'] = raw_dataset['name']\n",
    "\n",
    "# move name column to the first column\n",
    "reg_columns = [reg_dataset.columns[-1]] + list(reg_dataset.columns[:-1])\n",
    "reg_dataset = reg_dataset[reg_columns]\n",
    "\n",
    "\n",
    "reg_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bfd0f-0f7a-447c-93cc-293e6cf04fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "msk = np.random.rand(len(reg_dataset)) < 0.8\n",
    "train = reg_dataset[msk]\n",
    "test = reg_dataset[~msk]\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "x = np.asanyarray(train[['american', 'asian', 'casual',\n",
    "                         'european', 'latin', 'Oakland', \n",
    "                         'Emeryville', 'San Diego']])\n",
    "\n",
    "y = np.asanyarray(train[['likes']])\n",
    "regr.fit (x, y)\n",
    "\n",
    "# The coefficients\n",
    "\n",
    "print ('Coefficients: ', regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba2d68-3462-400d-aef9-64e731fd4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression Prediction Capabilities\n",
    "\n",
    "y_hat= regr.predict(test[['american', 'asian', 'casual',\n",
    "                         'european', 'latin', 'Oakland', \n",
    "                         'Emeryville', 'San Diego']])\n",
    "\n",
    "x = np.asanyarray(test[['american', 'asian', 'casual',\n",
    "                         'european', 'latin', 'Oakland', \n",
    "                         'Emeryville', 'San Diego']])\n",
    "\n",
    "y = np.asanyarray(test[['likes']])\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((y_hat - y) ** 2))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a35f1-9ff3-413d-94fc-a605331ce13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Ordinal Logistic Regression\n",
    "\n",
    "x_train = np.asanyarray(train[['american', 'asian', 'casual',\n",
    "                         'european', 'latin', 'Oakland', \n",
    "                         'Emeryville', 'San Diego']])\n",
    "\n",
    "y_train = np.asanyarray(train['ranking'])\n",
    "\n",
    "x_test = np.asanyarray(test[['american', 'asian', 'casual',\n",
    "                         'european', 'latin', 'Oakland', \n",
    "                         'Emeryville', 'San Diego']])\n",
    "\n",
    "y_test = np.asanyarray(test['ranking'])\n",
    "\n",
    "\n",
    "mul_ordinal = linear_model.LogisticRegression(multi_class='multinomial',\n",
    "                                              solver='newton-cg',\n",
    "                                              fit_intercept=True).fit(x_train,\n",
    "                                                                      y_train)\n",
    "\n",
    "mul_ordinal\n",
    "\n",
    "coef = mul_ordinal.coef_[0]\n",
    "print (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ada280-f0dd-4210-9330-2eba896847cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Ordinal Logistic Regression Prediction Capabilities\n",
    "\n",
    "yhat = mul_ordinal.predict(x_test)\n",
    "yhat\n",
    "\n",
    "yhat_prob = mul_ordinal.predict_proba(x_test)\n",
    "yhat_prob\n",
    "\n",
    "\n",
    "# average = None, average = 'micro', average = 'macro', or average = 'weighted'\n",
    "jaccard_score(y_test, yhat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d3022-b0f1-429e-af94-37bd2296660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f5d47-5281-406b-9c26-a3569fcba926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration of Coefficient Magnitudes of Full Dataset\n",
    "\n",
    "x_all = np.asanyarray(reg_dataset[['american', 'asian', 'casual',\n",
    "                                   'european', 'latin', 'Oakland', \n",
    "                                   'Emeryville', 'San Diego']])\n",
    "\n",
    "y_all = np.asanyarray(reg_dataset['ranking'])\n",
    "\n",
    "\n",
    "\n",
    "LR = linear_model.LogisticRegression(multi_class='multinomial',\n",
    "                                            solver='newton-cg',\n",
    "                                            fit_intercept=True).fit(x_all,\n",
    "                                                                    y_all)\n",
    "\n",
    "LR\n",
    "\n",
    "coef = LR.coef_[0]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09942002-5853-466f-9fb4-c7b7e5615b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
